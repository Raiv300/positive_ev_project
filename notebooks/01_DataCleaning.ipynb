{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8496a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ Loaded devig_utils from: c:\\Users\\mattr\\OneDrive\\Desktop\\Positive_EV_Project\\src\\Positive_EV_Repo\\data\\devig_utils.py\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "Sprint 2 - Data Cleaning Pipeline\n",
    "PGA Outrights Betting Project (2019-2024)\n",
    "=============================================================================\n",
    "\n",
    "PURPOSE:\n",
    "    Clean raw historical outrights data fetched from DataGolf API and prepare\n",
    "    it for exploratory data analysis (EDA) and modeling.\n",
    "\n",
    "INPUTS:\n",
    "    - Raw CSV from fetch_datagolf.py: data/interim/hist_outrights.csv\n",
    "    - Contains odds, outcomes, and metadata for PGA Tour winner markets\n",
    "\n",
    "OUTPUTS:\n",
    "    - Cleaned parquet file: data/processed/model_data_clean.parquet\n",
    "    - Analysis-ready dataset with de-vigged probabilities and binary target\n",
    "\n",
    "KEY STEPS:\n",
    "    1. Filter to win market only (exclude Top-10, etc.)\n",
    "    2. Parse outcomes to create binary winner flag (Y)\n",
    "    3. Construct event identifiers from timestamps\n",
    "    4. Validate data quality (winner counts, missing values)\n",
    "    5. Convert American odds to decimal and implied probabilities\n",
    "    6. Remove bookmaker vig using proportional de-vig method\n",
    "    7. Engineer features (field size, price rank, etc.)\n",
    "    8. Remove duplicates and validate final dataset\n",
    "    \n",
    "AUTHOR: Matt Raivel\n",
    "DATE: October 2024\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ============================================================================\n",
    "# PATH CONFIGURATION\n",
    "# ============================================================================\n",
    "# Add the directory containing devig_utils.py to Python's search path\n",
    "# Structure: notebooks/ → ../src/Positive_EV_Repo/data/devig_utils.py\n",
    "data_path = Path.cwd().parent / 'src' / 'Positive_EV_Repo' / 'data'\n",
    "\n",
    "if str(data_path) not in sys.path:\n",
    "    sys.path.append(str(data_path))\n",
    "    \n",
    "# ============================================================================\n",
    "# IMPORT CUSTOM UTILITIES\n",
    "# ============================================================================\n",
    "# These functions handle odds conversion and vig removal\n",
    "# See devig_utils.py for implementation details\n",
    "from devig_utils import (\n",
    "    american_to_decimal,      # Convert +150 → 2.50 decimal odds\n",
    "    implied_from_american,    # Convert +150 → 0.40 implied probability\n",
    "    proportional_devig        # Remove bookmaker margin to get fair probabilities\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY SETTINGS\n",
    "# ============================================================================\n",
    "# Configure pandas to show all columns and format floats consistently\n",
    "pd.set_option('display.max_columns', None)           # Show all columns (no truncation)\n",
    "pd.set_option('display.max_rows', 100)               # Show up to 100 rows\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)  # 6 decimal places for floats\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"✓ Loaded devig_utils from: {data_path / 'devig_utils.py'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7885cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING RAW DATA\n",
      "======================================================================\n",
      "\n",
      "✓ Loaded from: c:\\Users\\mattr\\OneDrive\\Desktop\\Positive_EV_Project\\data\\interim\\hist_outrights.csv\n",
      "Raw data shape: 624 rows × 13 columns\n",
      "\n",
      "Columns (13):\n",
      "['bet_outcome_numeric', 'bet_outcome_text', 'close_odds', 'close_time', 'dg_id', 'open_odds', 'open_time', 'outcome', 'player_name', 'tour', 'year', 'book', 'market']\n",
      "\n",
      "Data types:\n",
      "bet_outcome_numeric    float64\n",
      "bet_outcome_text        object\n",
      "close_odds               int64\n",
      "close_time              object\n",
      "dg_id                    int64\n",
      "open_odds                int64\n",
      "open_time               object\n",
      "outcome                 object\n",
      "player_name             object\n",
      "tour                    object\n",
      "year                     int64\n",
      "book                    object\n",
      "market                  object\n",
      "dtype: object\n",
      "\n",
      "First 3 rows (preview):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bet_outcome_numeric</th>\n",
       "      <th>bet_outcome_text</th>\n",
       "      <th>close_odds</th>\n",
       "      <th>close_time</th>\n",
       "      <th>dg_id</th>\n",
       "      <th>open_odds</th>\n",
       "      <th>open_time</th>\n",
       "      <th>outcome</th>\n",
       "      <th>player_name</th>\n",
       "      <th>tour</th>\n",
       "      <th>year</th>\n",
       "      <th>book</th>\n",
       "      <th>market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>paid in full</td>\n",
       "      <td>1000</td>\n",
       "      <td>2025-10-08 15:37</td>\n",
       "      <td>19895</td>\n",
       "      <td>1000</td>\n",
       "      <td>2025-10-06 14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>pga</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>loss</td>\n",
       "      <td>1600</td>\n",
       "      <td>2025-10-08 15:37</td>\n",
       "      <td>22085</td>\n",
       "      <td>1600</td>\n",
       "      <td>2025-10-06 14:00</td>\n",
       "      <td>T14</td>\n",
       "      <td>Morikawa, Collin</td>\n",
       "      <td>pga</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>loss</td>\n",
       "      <td>1800</td>\n",
       "      <td>2025-10-08 15:37</td>\n",
       "      <td>13562</td>\n",
       "      <td>1800</td>\n",
       "      <td>2025-10-06 14:00</td>\n",
       "      <td>T20</td>\n",
       "      <td>Matsuyama, Hideki</td>\n",
       "      <td>pga</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bet_outcome_numeric bet_outcome_text  close_odds        close_time  dg_id  \\\n",
       "0             1.000000     paid in full        1000  2025-10-08 15:37  19895   \n",
       "1             0.000000             loss        1600  2025-10-08 15:37  22085   \n",
       "2             0.000000             loss        1800  2025-10-08 15:37  13562   \n",
       "\n",
       "   open_odds         open_time outcome         player_name tour  year  \\\n",
       "0       1000  2025-10-06 14:00       1  Schauffele, Xander  pga  2023   \n",
       "1       1600  2025-10-06 14:00     T14    Morikawa, Collin  pga  2023   \n",
       "2       1800  2025-10-06 14:00     T20   Matsuyama, Hideki  pga  2023   \n",
       "\n",
       "         book market  \n",
       "0  draftkings    win  \n",
       "1  draftkings    win  \n",
       "2  draftkings    win  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Load Raw Historical Outrights Data\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Locate and load the raw CSV file containing historical betting odds\n",
    "      and tournament outcomes fetched from DataGolf API.\n",
    "\n",
    "DATA SOURCE: fetch_datagolf.py saves to data/interim/hist_outrights.csv\n",
    "             (relative to where the script was executed)\n",
    "\n",
    "EXPECTED COLUMNS:\n",
    "    - bet_outcome_numeric: Binary indicator if bet paid (1) or lost (0)\n",
    "    - close_odds: American odds at market close (e.g., \"+1000\")\n",
    "    - close_time: Timestamp when odds were finalized\n",
    "    - dg_id: DataGolf's unique player identifier (join key)\n",
    "    - player_name: Golfer's name (\"Last, First\" format)\n",
    "    - outcome: Finish position (\"1\", \"T14\", \"CUT\", etc.)\n",
    "    - year: Tournament year\n",
    "    - book: Sportsbook name (e.g., \"draftkings\")\n",
    "    - market: Bet type (\"win\" or \"top_10\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING RAW DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# FILE LOCATION LOGIC\n",
    "# ============================================================================\n",
    "# The fetch script may run from different locations, so we check multiple paths\n",
    "project_root = Path.cwd().parent  # Go up one level from notebooks/ to project root\n",
    "\n",
    "# Define potential locations (in order of likelihood)\n",
    "possible_paths = [\n",
    "    project_root / 'data' / 'interim' / 'hist_outrights.csv',              # Standard location\n",
    "    project_root / 'src' / 'Positive_EV_Repo' / 'data' / 'interim' / 'hist_outrights.csv',  # Alt location\n",
    "]\n",
    "\n",
    "# Try each path until we find the file\n",
    "raw_path = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        raw_path = path\n",
    "        break\n",
    "\n",
    "# If not found in expected locations, search entire project\n",
    "if raw_path is None:\n",
    "    print(\"⚠️  File not found in expected locations. Searching project...\")\n",
    "    found = list(project_root.rglob('hist_outrights.csv'))\n",
    "    \n",
    "    if found:\n",
    "        raw_path = found[0]\n",
    "        print(f\"⚠️  Found file at unexpected location: {raw_path}\")\n",
    "    else:\n",
    "        # File doesn't exist - provide helpful error message\n",
    "        raise FileNotFoundError(\n",
    "            \"hist_outrights.csv not found. Please run fetch_datagolf.py first:\\n\"\n",
    "            \"  cd src/Positive_EV_Repo/data\\n\"\n",
    "            \"  python fetch_datagolf.py\"\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "\n",
    "# ============================================================================\n",
    "# INITIAL DATA INSPECTION\n",
    "# ============================================================================\n",
    "print(f\"\\n✓ Loaded from: {raw_path}\")\n",
    "print(f\"Raw data shape: {df_raw.shape[0]:,} rows × {df_raw.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\nColumns ({len(df_raw.columns)}):\")\n",
    "print(df_raw.columns.tolist())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "print(f\"\\nFirst 3 rows (preview):\")\n",
    "display(df_raw.head(3))  # Use display() for better notebook formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f37a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIAL DATA QUALITY ASSESSMENT\n",
      "======================================================================\n",
      "\n",
      "1. Market Types:\n",
      "market\n",
      "win       312\n",
      "top_10    312\n",
      "Name: count, dtype: int64\n",
      "   → We will filter to 'win' market only (outrights)\n",
      "\n",
      "2. Sportsbook Coverage:\n",
      "book\n",
      "draftkings    312\n",
      "fanduel       312\n",
      "Name: count, dtype: int64\n",
      "   → Total books: 2\n",
      "\n",
      "3. Year Distribution:\n",
      "year\n",
      "2023    312\n",
      "2024    312\n",
      "Name: count, dtype: int64\n",
      "   → Coverage: 2023 to 2024\n",
      "\n",
      "4. Missing Data:\n",
      "  ✓ No missing values detected!\n",
      "\n",
      "5. Event Identification:\n",
      "  ⚠️  No event_id column found\n",
      "     → Will construct from date/timestamp in next step\n",
      "\n",
      "======================================================================\n",
      "✓ Initial assessment complete\n",
      "  Next: Filter to win market and parse outcomes\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Initial Data Quality Assessment\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Understand the raw data before cleaning - identify issues that need\n",
    "      to be addressed (missing values, duplicate markets, year coverage, etc.)\n",
    "\n",
    "CHECKS:\n",
    "    1. What markets are present? (win, top_10, etc.)\n",
    "    2. Which sportsbooks provided data?\n",
    "    3. What years are covered?\n",
    "    4. Are there missing values? Where?\n",
    "    5. Do we have event identifiers for grouping?\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INITIAL DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. MARKET TYPES\n",
    "# ============================================================================\n",
    "# DataGolf API returns multiple bet types - we only want \"win\" (outright winner)\n",
    "print(\"\\n1. Market Types:\")\n",
    "print(df_raw['market'].value_counts())\n",
    "print(f\"   → We will filter to 'win' market only (outrights)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SPORTSBOOK COVERAGE\n",
    "# ============================================================================\n",
    "# Different books may have different odds/margins - document what we have\n",
    "print(\"\\n2. Sportsbook Coverage:\")\n",
    "print(df_raw['book'].value_counts())\n",
    "print(f\"   → Total books: {df_raw['book'].nunique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. TEMPORAL COVERAGE\n",
    "# ============================================================================\n",
    "# Check what years we successfully fetched\n",
    "print(\"\\n3. Year Distribution:\")\n",
    "year_counts = df_raw['year'].value_counts().sort_index()\n",
    "print(year_counts)\n",
    "print(f\"   → Coverage: {year_counts.index.min()} to {year_counts.index.max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MISSING DATA ANALYSIS\n",
    "# ============================================================================\n",
    "# Identify columns with missing values and quantify missingness\n",
    "print(\"\\n4. Missing Data:\")\n",
    "missing = df_raw.isnull().sum()  # Count nulls per column\n",
    "missing_pct = 100 * missing / len(df_raw)  # Convert to percentage\n",
    "\n",
    "# Create summary table sorted by most missing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "\n",
    "# Only show columns that have missing data\n",
    "missing_subset = missing_df[missing_df['Percentage'] > 0]\n",
    "\n",
    "if len(missing_subset) > 0:\n",
    "    print(missing_subset)\n",
    "    print(f\"\\n   → {len(missing_subset)} columns have missing values\")\n",
    "else:\n",
    "    print(\"  ✓ No missing values detected!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. EVENT IDENTIFICATION\n",
    "# ============================================================================\n",
    "# Check if we have a clean event_id column or need to construct one\n",
    "print(\"\\n5. Event Identification:\")\n",
    "if 'event_id' in df_raw.columns:\n",
    "    print(f\"  ✓ event_id column present\")\n",
    "    print(f\"  Unique events: {df_raw['event_id'].nunique():,}\")\n",
    "    \n",
    "    # Check if event_id has nulls\n",
    "    if df_raw['event_id'].isna().any():\n",
    "        print(f\"  ⚠️  {df_raw['event_id'].isna().sum()} rows have missing event_id\")\n",
    "else:\n",
    "    print(\"  ⚠️  No event_id column found\")\n",
    "    print(\"     → Will construct from date/timestamp in next step\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"✓ Initial assessment complete\")\n",
    "print(f\"  Next: Filter to win market and parse outcomes\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5072c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: FILTER TO WIN MARKET\n",
      "======================================================================\n",
      "\n",
      "Starting dataset:\n",
      "  Total rows: 624\n",
      "  Market breakdown:\n",
      "market\n",
      "win       312\n",
      "top_10    312\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After filtering to 'win' market:\n",
      "  Remaining rows: 312\n",
      "  Dropped rows (other markets): 312\n",
      "  Percentage retained: 50.0%\n",
      "\n",
      "✓ Filter successful - dataset contains only outright winner bets\n",
      "\n",
      "Sample of win market data (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>close_odds</th>\n",
       "      <th>outcome</th>\n",
       "      <th>year</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morikawa, Collin</td>\n",
       "      <td>1600</td>\n",
       "      <td>T14</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matsuyama, Hideki</td>\n",
       "      <td>1800</td>\n",
       "      <td>T20</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gotterup, Chris</td>\n",
       "      <td>2000</td>\n",
       "      <td>T40</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noren, Alex</td>\n",
       "      <td>2200</td>\n",
       "      <td>T27</td>\n",
       "      <td>2023</td>\n",
       "      <td>draftkings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          player_name  close_odds outcome  year        book\n",
       "0  Schauffele, Xander        1000       1  2023  draftkings\n",
       "1    Morikawa, Collin        1600     T14  2023  draftkings\n",
       "2   Matsuyama, Hideki        1800     T20  2023  draftkings\n",
       "3     Gotterup, Chris        2000     T40  2023  draftkings\n",
       "4         Noren, Alex        2200     T27  2023  draftkings"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Filter to Win Market Only\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Isolate outright winner bets and remove other market types\n",
    "\n",
    "RATIONALE:\n",
    "    - Project scope is predicting WINNERS (1st place finish)\n",
    "    - Top-10, Top-20, etc. are different prediction problems\n",
    "    - Different markets have different vig structures\n",
    "    - Keeping multiple markets would require separate models\n",
    "\n",
    "INPUT: df_raw with multiple markets\n",
    "OUTPUT: df_win containing only 'win' market rows\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: FILTER TO WIN MARKET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# COUNT BEFORE FILTERING\n",
    "# ============================================================================\n",
    "initial_count = len(df_raw)\n",
    "print(f\"\\nStarting dataset:\")\n",
    "print(f\"  Total rows: {initial_count:,}\")\n",
    "print(f\"  Market breakdown:\")\n",
    "print(df_raw['market'].value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# APPLY FILTER\n",
    "# ============================================================================\n",
    "# Keep only rows where market == 'win'\n",
    "# Use .copy() to avoid SettingWithCopyWarning in later operations\n",
    "df_win = df_raw[df_raw['market'] == 'win'].copy()\n",
    "\n",
    "# ============================================================================\n",
    "# COUNT AFTER FILTERING\n",
    "# ============================================================================\n",
    "dropped_count = initial_count - len(df_win)\n",
    "\n",
    "print(f\"\\nAfter filtering to 'win' market:\")\n",
    "print(f\"  Remaining rows: {len(df_win):,}\")\n",
    "print(f\"  Dropped rows (other markets): {dropped_count:,}\")\n",
    "print(f\"  Percentage retained: {100 * len(df_win) / initial_count:.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# SANITY CHECK\n",
    "# ============================================================================\n",
    "# Verify that we only have 'win' market now\n",
    "assert df_win['market'].nunique() == 1, \"ERROR: Multiple markets still present!\"\n",
    "assert df_win['market'].iloc[0] == 'win', \"ERROR: Wrong market retained!\"\n",
    "\n",
    "print(f\"\\n✓ Filter successful - dataset contains only outright winner bets\")\n",
    "\n",
    "# Show sample of filtered data\n",
    "print(f\"\\nSample of win market data (first 5 rows):\")\n",
    "display(df_win[['player_name', 'close_odds', 'outcome', 'year', 'book']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a8f27d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: PARSE OUTCOMES TO CREATE TARGET (Y)\n",
      "======================================================================\n",
      "Parsing Outcomes...\n",
      "\n",
      "✓ Target variable (Y) created:\n",
      "\n",
      "Value counts:\n",
      "Y\n",
      "0    308\n",
      "1      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Overall Win Rate: 0.012821(1.2821%)\n",
      "\n",
      "✓ No missing outcomes - all events have results\n",
      "\n",
      "Winners per year:\n",
      "year\n",
      "2023    2\n",
      "2024    2\n",
      "Name: Y, dtype: int64\n",
      "\n",
      "   → Typical PGA Tour season has ~45 events\n",
      "   → Our data has 2.0 winners per year (avg)\n",
      "\n",
      "Sample outcome parsing (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morikawa, Collin</td>\n",
       "      <td>T14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matsuyama, Hideki</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gotterup, Chris</td>\n",
       "      <td>T40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noren, Alex</td>\n",
       "      <td>T27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kitayama, Kurt</td>\n",
       "      <td>T48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kim, Si Woo</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hojgaard, Rasmus</td>\n",
       "      <td>T14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yu, Kevin</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thorbjornsen, Michael</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             player_name outcome  Y\n",
       "0     Schauffele, Xander       1  1\n",
       "1       Morikawa, Collin     T14  0\n",
       "2      Matsuyama, Hideki     T20  0\n",
       "3        Gotterup, Chris     T40  0\n",
       "4            Noren, Alex     T27  0\n",
       "5         Kitayama, Kurt     T48  0\n",
       "6            Kim, Si Woo     T20  0\n",
       "7       Hojgaard, Rasmus     T14  0\n",
       "8              Yu, Kevin     T20  0\n",
       "9  Thorbjornsen, Michael       3  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Parse Outcomes to Create Target (Y)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: PARSE OUTCOMES TO CREATE TARGET (Y)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def parse_outcome_to_winner(outcome_str):\n",
    "    \"\"\"\n",
    "    Convert DataGolf outcome string to binary winner flag.\n",
    "\n",
    "    Examples\"\n",
    "    \"1\" -> 1 (sole winner)\n",
    "    \"T1\" -> 2 (co-winner in playoff, very rare)\n",
    "    \"2\" -> 0 (2nd place)\n",
    "    \"T14\" -> 0 (tied 14th)\n",
    "    \"Cut\" -> 0 (missed cut)\n",
    "    \"WD\" -> 0 (Withdrew)\n",
    "\n",
    "    TARGET VARIABLE (Y):\n",
    "    1 = Player won the tournament\n",
    "    2 = Player did not win\n",
    "\n",
    "    EDGE CASES:\n",
    "    - Playoffs: Multiple players tied for 1st go to sudden death,\n",
    "    DataGolf marks winner as \"1\", playoff losers as \"2\" or \"T2\".\n",
    "    - Co-winners: Very Rare (called due to darkness or weather) both players\n",
    "    marked as \"T1\" -> both get Y=1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "#===================================================================================================================\n",
    "# DEFINE PARSING FUNCTION\n",
    "#====================================================================================================================\n",
    "\n",
    "def parse_outcome_to_winner(outcome_str):\n",
    "    \"\"\"\n",
    "    Convert Datagolf outcome string to binary winner flag.\n",
    "\n",
    "    Logic:\n",
    "    - Winner is indicated by exactly \"1\" (no tie) or T1 (co-winner)\n",
    "    - Everything else (2nd place, missed cut, etc) is 0\n",
    "    - Missing outcomes return NaN for later investigation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    outcome_str : str or NaN\n",
    "        Finish position string from DataGolf\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> parse_outcome_to_winner(\"1\")\n",
    "    1\n",
    "    >>> parse_outcome_to_winner(\"T1\")\n",
    "    1\n",
    "    >>> parse_outcome_to_winner(\"2\")\n",
    "    0\n",
    "    >>> parse_outcome_to_winner(\"T14\")\n",
    "    0\n",
    "    >>> parse_outcome_to_winner(\"CUT\")\n",
    "    0\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(outcome_str):\n",
    "        return np.nan\n",
    "\n",
    "    #Standardize: convert string, strip white space, uppercase\n",
    "    outcome_str = str(outcome_str).strip().upper()\n",
    "\n",
    "    #Winner check: exactly \"1\" or \"T1\"\n",
    "    if outcome_str in [\"1\", \"T1\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# APPLY PARSING TO ENTIRE DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Parsing Outcomes...\")\n",
    "df_win['Y'] = df_win['outcome'].apply(parse_outcome_to_winner)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TARGET VARIABLE SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n✓ Target variable (Y) created:\")\n",
    "print(f\"\\nValue counts:\")\n",
    "print(df_win['Y'].value_counts())\n",
    "\n",
    "#Calculate wini rate ( should be 0.8% for typical field size of 120-150)\n",
    "win_rate = df_win[\"Y\"].mean()\n",
    "print(f'\\n Overall Win Rate: {win_rate:.6f}({100*win_rate:.4f}%)')\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MISSING OUTCOME CHECK\n",
    "# ============================================================================\n",
    "\n",
    "#if some outcome sare missing we need to see why\n",
    "\n",
    "missing_outcomes = df_win[\"Y\"].isna().sum()\n",
    "\n",
    "if missing_outcomes > 0:\n",
    "    print(f\"\\n  WARNING: {missing_outcomes} rows have missing outcomes\")\n",
    "    print(\"   This could indicate:\")\n",
    "    print(\"   - Tournament was canceled/postponed\")\n",
    "    print(\"   - Data collection error\")\n",
    "    print(\"   - Event is ongoing (live odds)\")\n",
    "    \n",
    "    print(\"\\nSample rows with missing outcome:\")\n",
    "    missing_sample = df_win[df_win['Y'].isna()][['player_name', 'outcome', 'year', 'event_id']].head()\n",
    "    display(missing_sample)\n",
    "    \n",
    "    # Decision point: Drop these rows or investigate further?\n",
    "    print(\"\\n   → These rows will be flagged for potential removal\")\n",
    "else:\n",
    "    print(\"\\n✓ No missing outcomes - all events have results\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUTION BY YEAR\n",
    "# ============================================================================\n",
    "# Check that we have winners in each year (sanity check for data completeness)\n",
    "print(\"\\nWinners per year:\")\n",
    "winners_by_year = df_win.groupby('year')['Y'].sum()\n",
    "print(winners_by_year)\n",
    "\n",
    "# Expected: ~40-50 PGA Tour events per year\n",
    "print(f\"\\n   → Typical PGA Tour season has ~45 events\")\n",
    "print(f\"   → Our data has {winners_by_year.mean():.1f} winners per year (avg)\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAMPLE OUTCOMES\n",
    "# ============================================================================\n",
    "# Show examples of parsed outcomes for verification\n",
    "print(\"\\nSample outcome parsing (first 10 rows):\")\n",
    "sample_outcomes = df_win[['player_name', 'outcome', 'Y']].head(10)\n",
    "display(sample_outcomes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7dcec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing timestamp columns...\n",
      "ALL timestamps parsed successfully! \n",
      "\n",
      "No event_id column found. Constructing from year + close_time...\n",
      "✓ Created event_id from year + close_time\n",
      "\n",
      "Event summary:\n",
      "  Unique events: 2\n",
      "  Date range: 2025-10-08 to 2025-10-08\n",
      "\n",
      "Field sizes (players per event):\n",
      "count     2.000000\n",
      "mean    156.000000\n",
      "std       0.000000\n",
      "min     156.000000\n",
      "25%     156.000000\n",
      "50%     156.000000\n",
      "75%     156.000000\n",
      "max     156.000000\n",
      "dtype: float64\n",
      "\n",
      "Smallest events (top 5):\n",
      "event_id\n",
      "2023_2025-10-08    156\n",
      "2024_2025-10-08    156\n",
      "dtype: int64\n",
      "\n",
      "Largest events (top 5):\n",
      "event_id\n",
      "2023_2025-10-08    156\n",
      "2024_2025-10-08    156\n",
      "dtype: int64\n",
      "\n",
      "Sample event: 2023_2025-10-08\n",
      "Field size: 156 players\n",
      "\n",
      "Top 10 players (by odds) in this event:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>close_odds</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morikawa, Collin</td>\n",
       "      <td>1600</td>\n",
       "      <td>T14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matsuyama, Hideki</td>\n",
       "      <td>1800</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gotterup, Chris</td>\n",
       "      <td>2000</td>\n",
       "      <td>T40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noren, Alex</td>\n",
       "      <td>2200</td>\n",
       "      <td>T27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kitayama, Kurt</td>\n",
       "      <td>2200</td>\n",
       "      <td>T48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kim, Si Woo</td>\n",
       "      <td>2200</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hojgaard, Rasmus</td>\n",
       "      <td>2200</td>\n",
       "      <td>T14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yu, Kevin</td>\n",
       "      <td>2800</td>\n",
       "      <td>T20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thorbjornsen, Michael</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             player_name  close_odds outcome  Y\n",
       "0     Schauffele, Xander        1000       1  1\n",
       "1       Morikawa, Collin        1600     T14  0\n",
       "2      Matsuyama, Hideki        1800     T20  0\n",
       "3        Gotterup, Chris        2000     T40  0\n",
       "4            Noren, Alex        2200     T27  0\n",
       "5         Kitayama, Kurt        2200     T48  0\n",
       "6            Kim, Si Woo        2200     T20  0\n",
       "7       Hojgaard, Rasmus        2200     T14  0\n",
       "8              Yu, Kevin        2800     T20  0\n",
       "9  Thorbjornsen, Michael        3000       3  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Create Event Identifier for Grouping\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Goal: Create a unique identifier for each tournament event\n",
    "\n",
    "Why?\n",
    "- We need to group players by event for de-vigging (vig removal)\n",
    "- Calculate per event statistics(field size, overround)\n",
    "- Validate that each event has exactly one winner\n",
    "- Time series train/validation/test splits\n",
    "\n",
    "Strategy:\n",
    "if event_id column exists:\n",
    "    -> use it directly\n",
    "\n",
    "If not:\n",
    "    -> Construct from year + close_time date\n",
    "    -> Assumption: only one PGA tour event per day\n",
    "    -> Format: \"2023_2023-10-08 (year_date)\n",
    "\n",
    "\n",
    "TIMESTAMP FIELDS:\n",
    "- open_time : when odds first posted (Monday before tournament)\n",
    "- close_time: when odds finalize (typically Wednesday evening)\n",
    "- We use close time as canonical decision timestamp\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PARSE TIMESTAMPS\n",
    "# ============================================================================\n",
    "# Convert string timestamps to pandas datetime objects for manipulation\n",
    "print(\"\\nParsing timestamp columns...\")\n",
    "\n",
    "df_win['close_time_dt'] = pd.to_datetime(df_win['close_time'], errors = 'coerce')\n",
    "df_win['open_time_dt'] = pd.to_datetime(df_win['open_time'], errors = 'coerce')\n",
    "\n",
    "#Check for any unparseable dates\n",
    "bad_close = df_win['close_time_dt'].isna().sum()\n",
    "bad_open = df_win['open_time_dt'].isna().sum()\n",
    "\n",
    "if bad_close > 0:\n",
    "    print(f\"{bad_close} rows have invalid close_time\")\n",
    "\n",
    "if bad_open < 0:\n",
    "    print(f'{bad_open} rows have invald open_time')\n",
    "\n",
    "if bad_close == 0 and bad_open == 0:\n",
    "    print(\"ALL timestamps parsed successfully! \")\n",
    "\n",
    "\n",
    "#============================================================================\n",
    "# EXTRACT DATE (without time component)\n",
    "# ============================================================================\n",
    "# Create date-only column for grouping (ignore hours/minutes)\n",
    "# Assumption: All odds for same event have same close_time date\n",
    "df_win['event_date'] = df_win['close_time_dt'].dt.date\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE OR VERIFY EVENT_ID\n",
    "# ============================================================================\n",
    "if 'event_id' not in df_win.columns:\n",
    "    # No event_id in data - construct one\n",
    "    print(\"\\nNo event_id column found. Constructing from year + close_time...\")\n",
    "    \n",
    "    # Format: \"YEAR_YYYY-MM-DD\"\n",
    "    # Example: \"2023_2023-10-08\" for ZOZO Championship\n",
    "    df_win['event_id'] = (\n",
    "        df_win['year'].astype(str) + '_' + \n",
    "        df_win['event_date'].astype(str)\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Created event_id from year + close_time\")\n",
    "else:\n",
    "    # event_id already exists - just verify it's usable\n",
    "    print(f\"✓ event_id column already exists in data\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EVENT SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "print(f\"\\nEvent summary:\")\n",
    "print(f\"  Unique events: {df_win['event_id'].nunique():,}\")\n",
    "print(f\"  Date range: {df_win['event_date'].min()} to {df_win['event_date'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIELD SIZE DISTRIBUTION\n",
    "# ============================================================================\n",
    "# How many players per event? Important for understanding market structure\n",
    "event_sizes = df_win.groupby('event_id').size()\n",
    "\n",
    "print(f\"\\nField sizes (players per event):\")\n",
    "print(event_sizes.describe())\n",
    "\n",
    "# Flag unusually small or large events\n",
    "print(f\"\\nSmallest events (top 5):\")\n",
    "print(event_sizes.nsmallest(5))\n",
    "\n",
    "print(f\"\\nLargest events (top 5):\")\n",
    "print(event_sizes.nlargest(5))\n",
    "\n",
    "# PGA Tour typical range: 120-156 players\n",
    "small_events = (event_sizes < 100).sum()\n",
    "large_events = (event_sizes > 160).sum()\n",
    "\n",
    "if small_events > 0:\n",
    "    print(f\"\\n  ⚠️  {small_events} events have < 100 players (invitational/limited field?)\")\n",
    "if large_events > 0:\n",
    "    print(f\"\\n  ⚠️  {large_events} events have > 160 players (unusual)\")\n",
    "\n",
    "# ============================================================================\n",
    "# SHOW SAMPLE EVENT\n",
    "# ============================================================================\n",
    "# Display one complete event to verify structure\n",
    "sample_event = event_sizes.index[0]\n",
    "print(f\"\\nSample event: {sample_event}\")\n",
    "print(f\"Field size: {event_sizes[sample_event]} players\")\n",
    "\n",
    "sample_event_data = df_win[df_win['event_id'] == sample_event][\n",
    "    ['player_name', 'close_odds', 'outcome', 'Y']\n",
    "].head(10)\n",
    "\n",
    "print(f\"\\nTop 10 players (by odds) in this event:\")\n",
    "display(sample_event_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff873eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RECOVERY: Checking and recreating event_id if needed\n",
      "======================================================================\n",
      "✓ event_id exists: 2 unique events\n",
      "\n",
      "Dataset check:\n",
      "  Rows: 312\n",
      "  Events: 2\n",
      "  Players: 78\n",
      "\n",
      "Required columns present:\n",
      "  event_id: True\n",
      "  dg_id: True\n",
      "  implied_raw: False\n",
      "  dec_odds: False\n",
      "  Y: True\n"
     ]
    }
   ],
   "source": [
    "# RECOVERY CELL: Recreate event_id if missing\n",
    "print(\"=\"*70)\n",
    "print(\"RECOVERY: Checking and recreating event_id if needed\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'event_id' not in df_win.columns:\n",
    "    print(\"\\n⚠️  event_id missing - recreating from timestamps...\")\n",
    "    \n",
    "    # Parse timestamps if needed\n",
    "    if 'close_time_dt' not in df_win.columns:\n",
    "        df_win['close_time_dt'] = pd.to_datetime(df_win['close_time'], errors='coerce')\n",
    "    \n",
    "    # Create event_date\n",
    "    df_win['event_date'] = df_win['close_time_dt'].dt.date\n",
    "    \n",
    "    # Recreate event_id\n",
    "    df_win['event_id'] = (\n",
    "        df_win['year'].astype(str) + '_' + \n",
    "        df_win['event_date'].astype(str)\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Recreated event_id: {df_win['event_id'].nunique()} unique events\")\n",
    "else:\n",
    "    print(f\"✓ event_id exists: {df_win['event_id'].nunique()} unique events\")\n",
    "\n",
    "# Verify we have what we need\n",
    "print(f\"\\nDataset check:\")\n",
    "print(f\"  Rows: {len(df_win):,}\")\n",
    "print(f\"  Events: {df_win['event_id'].nunique():,}\")\n",
    "print(f\"  Players: {df_win['dg_id'].nunique():,}\")\n",
    "print(f\"\\nRequired columns present:\")\n",
    "for col in ['event_id', 'dg_id', 'implied_raw', 'dec_odds', 'Y']:\n",
    "    print(f\"  {col}: {col in df_win.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b080af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner count validation:\n",
      "  Total events: 2\n",
      "  Events with exactly 1 winner: 0 (0.0%)\n",
      "  Events with 0 winners: 0\n",
      "  Events with 2+ winners: 2\n",
      "\n",
      "======================================================================\n",
      "⚠️  ISSUE: 2 events have MULTIPLE winners\n",
      "======================================================================\n",
      "\n",
      "Events with 2+ winners:\n",
      "event_id\n",
      "2023_2025-10-08    2\n",
      "2024_2025-10-08    2\n",
      "Name: Y, dtype: int64\n",
      "\n",
      "Sample data from event: 2023_2025-10-08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Y</th>\n",
       "      <th>book</th>\n",
       "      <th>close_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023_2025-10-08</td>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>draftkings</td>\n",
       "      <td>2025-10-08 15:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2023_2025-10-08</td>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>2025-10-08 15:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event_id         player_name outcome  Y        book  \\\n",
       "0    2023_2025-10-08  Schauffele, Xander       1  1  draftkings   \n",
       "156  2023_2025-10-08  Schauffele, Xander       1  1     fanduel   \n",
       "\n",
       "           close_time  \n",
       "0    2025-10-08 15:37  \n",
       "156  2025-10-08 15:37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible causes:\n",
      "  - True co-winners (tied 1st, no playoff) - RARE but valid\n",
      "  - Duplicate rows not yet removed (same player, multiple books/times)\n",
      "  → Will be resolved in deduplication step (Cell 12)\n",
      "\n",
      "======================================================================\n",
      "✓ Flagging complete:\n",
      "  Flagged rows: 312 (in 2 events)\n",
      "  Clean rows: 0 (in 0 events)\n",
      "======================================================================\n",
      "\n",
      "⚠️  Note: Flagged events retained for now, will address in:\n",
      "     - Deduplication (Cell 12)\n",
      "     - Final validation (Cell 13)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Validate Winner Counts per Event\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "GOAL: Ensure data quality by checking that each event has exactly 1 winner\n",
    "\n",
    "EXPECTED: Every PGA tour event has exactly one winner\n",
    "- Even Playoffs result in a single winner.\n",
    "- Co-winners (T1) are extremely rare but would have Y=1\n",
    "\n",
    "DATA QUALITY ISSUES TO CATCH:\n",
    "1. Events with 0 winners\n",
    "    -> Missing outcome data\n",
    "    -> event was cancelled\n",
    "    -> Incomplete data pull\n",
    "\n",
    "  \n",
    "    2. Events with 2+ winners\n",
    "       → Duplicate rows (same player multiple times)\n",
    "       → Co-winner situation (rare but valid)\n",
    "       → Multiple books/timestamps not deduplicated yet\n",
    "\n",
    "ACTION: Flag problematic events for manual review or exclusion\n",
    "\"\"\" \n",
    "\n",
    "# ============================================================================\n",
    "# COUNT WINNERS PER EVENT\n",
    "# ============================================================================\n",
    "# Sum Y column (binary) per event → should equal 1\n",
    "\n",
    "winner_counts = df_win.groupby('event_id')[\"Y\"].sum()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "total_events = len(winner_counts)\n",
    "good_events = (winner_counts == 1).sum()\n",
    "zero_winner_events = (winner_counts == 0).sum()\n",
    "multi_winner_events = (winner_counts >1).sum()\n",
    "\n",
    "print(f\"\\nWinner count validation:\")\n",
    "print(f\"  Total events: {total_events:,}\")\n",
    "print(f\"  Events with exactly 1 winner: {good_events:,} ({100*good_events/total_events:.1f}%)\")\n",
    "print(f\"  Events with 0 winners: {zero_winner_events:,}\")\n",
    "print(f\"  Events with 2+ winners: {multi_winner_events:,}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INVESTIGATE ZERO-WINNER EVENTS\n",
    "# ============================================================================\n",
    "if zero_winner_events > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"⚠️  ISSUE: {zero_winner_events} events have NO winner\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    no_winner = winner_counts[winner_counts == 0]\n",
    "    \n",
    "    # Show list of problematic events\n",
    "    print(f\"\\nEvents with 0 winners:\")\n",
    "    print(no_winner.head(10))\n",
    "    \n",
    "    # Show sample data from one problematic event\n",
    "    sample_event = no_winner.index[0]\n",
    "    print(f\"\\nSample data from event: {sample_event}\")\n",
    "    sample_data = df_win[df_win['event_id'] == sample_event][\n",
    "        ['event_id', 'player_name', 'outcome', 'Y', 'year']\n",
    "    ].head()\n",
    "    display(sample_data)\n",
    "    \n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  - Tournament canceled/postponed\")\n",
    "    print(\"  - Incomplete data (still in progress)\")\n",
    "    print(\"  - Outcome parsing failed\")\n",
    "    print(\"  → Recommend: Exclude these events from modeling\")\n",
    "\n",
    "# ============================================================================\n",
    "# INVESTIGATE MULTI-WINNER EVENTS\n",
    "# ============================================================================\n",
    "if multi_winner_events > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"⚠️  ISSUE: {multi_winner_events} events have MULTIPLE winners\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    multi_winner = winner_counts[winner_counts > 1]\n",
    "    \n",
    "    # Show list of problematic events\n",
    "    print(f\"\\nEvents with 2+ winners:\")\n",
    "    print(multi_winner.head(10))\n",
    "    \n",
    "    # Show sample data from one problematic event\n",
    "    sample_event = multi_winner.index[0]\n",
    "    print(f\"\\nSample data from event: {sample_event}\")\n",
    "    sample_data = df_win[df_win['event_id'] == sample_event][\n",
    "        ['event_id', 'player_name', 'outcome', 'Y', 'book', 'close_time']\n",
    "    ]\n",
    "    \n",
    "    # Show only winners from this event\n",
    "    winners_only = sample_data[sample_data['Y'] == 1]\n",
    "    display(winners_only)\n",
    "    \n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  - True co-winners (tied 1st, no playoff) - RARE but valid\")\n",
    "    print(\"  - Duplicate rows not yet removed (same player, multiple books/times)\")\n",
    "    print(\"  → Will be resolved in deduplication step (Cell 12)\")\n",
    "\n",
    "# ============================================================================\n",
    "# FLAG PROBLEMATIC EVENTS\n",
    "# ============================================================================\n",
    "# Add column to mark rows in events with bad winner counts\n",
    "# We'll decide later whether to exclude or fix these\n",
    "problematic_event_ids = winner_counts[winner_counts != 1].index\n",
    "\n",
    "df_win['flag_bad_winner_count'] = df_win['event_id'].isin(problematic_event_ids)\n",
    "\n",
    "flagged_rows = df_win['flag_bad_winner_count'].sum()\n",
    "flagged_events = (winner_counts != 1).sum()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ Flagging complete:\")\n",
    "print(f\"  Flagged rows: {flagged_rows:,} (in {flagged_events} events)\")\n",
    "print(f\"  Clean rows: {len(df_win) - flagged_rows:,} (in {total_events - flagged_events} events)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if flagged_rows > 0:\n",
    "    print(f\"\\n⚠️  Note: Flagged events retained for now, will address in:\")\n",
    "    print(f\"     - Deduplication (Cell 12)\")\n",
    "    print(f\"     - Final validation (Cell 13)\")\n",
    "else:\n",
    "    print(f\"\\n✓ All events have exactly 1 winner - data quality excellent!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62a337c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5: CLEAN ODDS DATA\n",
      "======================================================================\n",
      "\n",
      "Checking for missing odds\n",
      "  close_odds null: 0\n",
      "  open_odds null: 0\n",
      "\n",
      "Validating American odds format...\n",
      "\n",
      "  Valid odds: 0\n",
      "  Invalid odds: 312\n",
      "\n",
      "⚠️  WARNING: 312 rows have invalid odds format\n",
      "\n",
      "Sample invalid odds (first 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>close_odds</th>\n",
       "      <th>year</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schauffele, Xander</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morikawa, Collin</td>\n",
       "      <td>1600</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matsuyama, Hideki</td>\n",
       "      <td>1800</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gotterup, Chris</td>\n",
       "      <td>2000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noren, Alex</td>\n",
       "      <td>2200</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kitayama, Kurt</td>\n",
       "      <td>2200</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kim, Si Woo</td>\n",
       "      <td>2200</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hojgaard, Rasmus</td>\n",
       "      <td>2200</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yu, Kevin</td>\n",
       "      <td>2800</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thorbjornsen, Michael</td>\n",
       "      <td>3000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_2025-10-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             player_name  close_odds  year         event_id\n",
       "0     Schauffele, Xander        1000  2023  2023_2025-10-08\n",
       "1       Morikawa, Collin        1600  2023  2023_2025-10-08\n",
       "2      Matsuyama, Hideki        1800  2023  2023_2025-10-08\n",
       "3        Gotterup, Chris        2000  2023  2023_2025-10-08\n",
       "4            Noren, Alex        2200  2023  2023_2025-10-08\n",
       "5         Kitayama, Kurt        2200  2023  2023_2025-10-08\n",
       "6            Kim, Si Woo        2200  2023  2023_2025-10-08\n",
       "7       Hojgaard, Rasmus        2200  2023  2023_2025-10-08\n",
       "8              Yu, Kevin        2800  2023  2023_2025-10-08\n",
       "9  Thorbjornsen, Michael        3000  2023  2023_2025-10-08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "✓ Odds cleaning complete:\n",
      "  Before: 312 rows\n",
      "  After:  0 rows\n",
      "  Dropped: 312 rows (100.00%)\n",
      "======================================================================\n",
      "\n",
      "Note: Dropped rows had missing or malformed odds\n",
      "      Cannot impute market prices - deletion is appropriate\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Clean Odds Data - Remove Missing & Invalid Values\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Ensure all odds are valid American format and non-null\n",
    "\n",
    "AMERICAN ODDS FORMAT:\n",
    "    Positive: +150 means bet $100 to win $150 (underdog)\n",
    "    Negative: -150 means bet $150 to win $100 (favorite)\n",
    "    \n",
    "VALID FORMATS:\n",
    "    ✓ \"+1000\"\n",
    "    ✓ \"-110\"\n",
    "    ✓ \"+250\"\n",
    "    ✗ \"1000\" (missing +/- sign)\n",
    "    ✗ \"N/A\" (non-numeric)\n",
    "    ✗ \"\" (empty string)\n",
    "\n",
    "WHY CRITICAL:\n",
    "    - Cannot convert to decimal odds without valid American odds\n",
    "    - Cannot calculate implied probabilities\n",
    "    - Cannot de-vig without probabilities\n",
    "    → Invalid odds = row must be dropped\n",
    "\n",
    "DECISION: Drop rows with missing/invalid odds (no imputation)\n",
    "    Rationale: Fabricating odds would create fake market signal\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 5: CLEAN ODDS DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK FOR NULL VALUES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nChecking for missing odds\")\n",
    "null_close = df_win['close_odds'].isna().sum()\n",
    "null_open = df_win['open_odds'].isna().sum()\n",
    "\n",
    "\n",
    "print(f\"  close_odds null: {null_close:,}\")\n",
    "print(f\"  open_odds null: {null_open:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATE AMERICAN ODDS FORMAT\n",
    "# ============================================================================\n",
    "print(\"\\nValidating American odds format...\")\n",
    "\n",
    "def is_valid_american_odds(odds_str):\n",
    "    \"\"\"\n",
    "    Check if string is valid American odds format.\n",
    "    \n",
    "    Valid: \"+150\", \"-110\", \"+2500\"\n",
    "    Invalid: \"150\" (no sign), \"N/A\", None, \"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    odds_str : str or NaN\n",
    "        Odds string to validate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if valid American odds format, False otherwise\n",
    "    \"\"\"\n",
    "    # Null values are invalid\n",
    "    if pd.isna(odds_str):\n",
    "        return False\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    odds_str = str(odds_str).strip()\n",
    "    \n",
    "    # Must start with + or -\n",
    "    if not (odds_str.startswith('+') or odds_str.startswith('-')):\n",
    "        return False\n",
    "    \n",
    "    # Everything after +/- must be numeric\n",
    "    try:\n",
    "        # Remove +/- sign and try to convert to integer\n",
    "        numeric_part = odds_str.replace('+', '').replace('-', '')\n",
    "        int(numeric_part)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        # Conversion failed - not a valid number\n",
    "        return False\n",
    "\n",
    "# Apply validation to close_odds column\n",
    "df_win['valid_odds'] = df_win['close_odds'].apply(is_valid_american_odds)\n",
    "\n",
    "# Count invalid odds\n",
    "invalid_count = (~df_win['valid_odds']).sum()\n",
    "\n",
    "print(f\"\\n  Valid odds: {df_win['valid_odds'].sum():,}\")\n",
    "print(f\"  Invalid odds: {invalid_count:,}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SHOW EXAMPLES OF INVALID ODDS\n",
    "# ============================================================================\n",
    "if invalid_count > 0:\n",
    "    print(f\"\\n⚠️  WARNING: {invalid_count} rows have invalid odds format\")\n",
    "    print(\"\\nSample invalid odds (first 10):\")\n",
    "    invalid_sample = df_win[~df_win['valid_odds']][\n",
    "        ['player_name', 'close_odds', 'year', 'event_id']\n",
    "    ].head(10)\n",
    "    display(invalid_sample)\n",
    "\n",
    "# ============================================================================\n",
    "# DROP INVALID ODDS\n",
    "# ============================================================================\n",
    "# Cannot proceed without valid odds - must drop these rows\n",
    "before_count = len(df_win)\n",
    "\n",
    "# Keep only rows with valid odds\n",
    "df_win = df_win[df_win['valid_odds']].copy()\n",
    "\n",
    "# Remove temporary validation column\n",
    "df_win.drop('valid_odds', axis=1, inplace=True)\n",
    "\n",
    "after_count = len(df_win)\n",
    "dropped = before_count - after_count\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ Odds cleaning complete:\")\n",
    "print(f\"  Before: {before_count:,} rows\")\n",
    "print(f\"  After:  {after_count:,} rows\")\n",
    "print(f\"  Dropped: {dropped:,} rows ({100*dropped/before_count:.2f}%)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if dropped > 0:\n",
    "    print(f\"\\nNote: Dropped rows had missing or malformed odds\")\n",
    "    print(f\"      Cannot impute market prices - deletion is appropriate\")\n",
    "else:\n",
    "    print(f\"\\n✓ No invalid odds found - all data retained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfa6c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 6: CONVERT ODDS & CALCULATE IMPLIED PROBABILITIES\n",
      "======================================================================\n",
      "\n",
      "Converting American odds to numeric...\n",
      "  ✓ Converted 0 odds to numeric format\n",
      "\n",
      "Converting to decimal odds...\n",
      "  ✓ Calculated decimal odds\n",
      "\n",
      "Calculating raw implied probabilities...\n",
      "  ✓ Calculated implied probabilities\n",
      "\n",
      "Sample conversions (first 10 rows):\n",
      "Empty DataFrame\n",
      "Columns: [player_name, close_odds, american_odds, dec_odds, implied_raw]\n",
      "Index: []\n",
      "\n",
      "======================================================================\n",
      "Validation checks:\n",
      "======================================================================\n",
      "  1. All decimal odds >= 1.0: True\n",
      "  2. All implied probs in (0, 1): True\n",
      "\n",
      "✓ Odds distribution summary:\n",
      "       dec_odds  implied_raw\n",
      "count  0.000000     0.000000\n",
      "mean        NaN          NaN\n",
      "std         NaN          NaN\n",
      "min         NaN          NaN\n",
      "25%         NaN          NaN\n",
      "50%         NaN          NaN\n",
      "75%         NaN          NaN\n",
      "max         NaN          NaN\n",
      "\n",
      "Interpretation:\n",
      "  Median decimal odds: nan (nan implied)\n",
      "  → Typical player has ~nan% win probability (before de-vig)\n",
      "\n",
      "  Min odds: nan (favorite)\n",
      "  Max odds: nan (extreme longshot)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Convert Odds to Decimal & Calculate Implied Probabilities\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Transform American odds into formats needed for analysis\n",
    "\n",
    "CONVERSIONS:\n",
    "    American → Decimal → Implied Probability\n",
    "    \n",
    "EXAMPLE:\n",
    "    American: +1000\n",
    "    Decimal:  11.0  (total return per $1 wagered, including stake)\n",
    "    Implied:  0.0909 (9.09% probability)\n",
    "\n",
    "WHY MULTIPLE FORMATS:\n",
    "    - Decimal odds: Easier to work with mathematically\n",
    "    - Implied probability: Raw market belief before vig removal\n",
    "    - Both needed: Decimal for EV calculations, implied for de-vigging\n",
    "\n",
    "FORMULAS:\n",
    "    If American > 0:  decimal = 1 + (American / 100)\n",
    "    If American < 0:  decimal = 1 + (100 / |American|)\n",
    "    \n",
    "    Implied probability = 1 / decimal\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 6: CONVERT ODDS & CALCULATE IMPLIED PROBABILITIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CONVERT STRING TO NUMERIC (ROBUST VERSION)\n",
    "# ============================================================================\n",
    "print(\"\\nConverting American odds to numeric...\")\n",
    "\n",
    "# Handle both string and numeric types\n",
    "def convert_american_odds(value):\n",
    "    \"\"\"Convert American odds (string or numeric) to integer\"\"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        return int(value)\n",
    "    # If string, remove + and spaces\n",
    "    return int(str(value).replace('+', '').replace(' ', ''))\n",
    "\n",
    "df_win['american_odds'] = df_win['close_odds'].apply(convert_american_odds)\n",
    "\n",
    "print(f\"  ✓ Converted {len(df_win):,} odds to numeric format\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONVERT TO DECIMAL ODDS\n",
    "# ============================================================================\n",
    "# Use utility function from devig_utils.py\n",
    "print(\"\\nConverting to decimal odds...\")\n",
    "\n",
    "df_win['dec_odds'] = american_to_decimal(df_win['american_odds'])\n",
    "\n",
    "print(f\"  ✓ Calculated decimal odds\")\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE IMPLIED PROBABILITIES\n",
    "# ============================================================================\n",
    "# This is the RAW implied probability BEFORE de-vigging\n",
    "# Sum of all implied probs per event will be > 1.0 (bookmaker overround)\n",
    "print(\"\\nCalculating raw implied probabilities...\")\n",
    "\n",
    "df_win['implied_raw'] = implied_from_american(df_win['american_odds'])\n",
    "\n",
    "print(f\"  ✓ Calculated implied probabilities\")\n",
    "\n",
    "# ============================================================================\n",
    "# SHOW CONVERSION EXAMPLES\n",
    "# ============================================================================\n",
    "print(\"\\nSample conversions (first 10 rows):\")\n",
    "conversion_cols = ['player_name', 'close_odds', 'american_odds', 'dec_odds', 'implied_raw']\n",
    "conversion_sample = df_win[conversion_cols].head(10)\n",
    "\n",
    "# Format for readability\n",
    "print(conversion_sample.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION CHECKS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Validation checks:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Check 1: All decimal odds should be >= 1.0\n",
    "all_decimal_valid = (df_win['dec_odds'] >= 1.0).all()\n",
    "print(f\"  1. All decimal odds >= 1.0: {all_decimal_valid}\")\n",
    "\n",
    "if not all_decimal_valid:\n",
    "    # Should never happen if conversion is correct\n",
    "    bad_decimal = df_win[df_win['dec_odds'] < 1.0]\n",
    "    print(f\"\\n     ⚠️  ERROR: {len(bad_decimal)} rows have decimal odds < 1.0\")\n",
    "    print(bad_decimal[['player_name', 'close_odds', 'american_odds', 'dec_odds']].head())\n",
    "\n",
    "# Check 2: All implied probabilities should be between 0 and 1\n",
    "all_implied_valid = ((df_win['implied_raw'] > 0) & (df_win['implied_raw'] < 1)).all()\n",
    "print(f\"  2. All implied probs in (0, 1): {all_implied_valid}\")\n",
    "\n",
    "if not all_implied_valid:\n",
    "    # Should never happen if conversion is correct\n",
    "    bad_implied = df_win[~((df_win['implied_raw'] > 0) & (df_win['implied_raw'] < 1))]\n",
    "    print(f\"\\n     ⚠️  ERROR: {len(bad_implied)} rows have implied prob out of bounds\")\n",
    "    print(bad_implied[['player_name', 'close_odds', 'implied_raw']].head())\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUTION SUMMARY\n",
    "# ============================================================================\n",
    "print(f\"\\n✓ Odds distribution summary:\")\n",
    "print(df_win[['dec_odds', 'implied_raw']].describe())\n",
    "\n",
    "# Interpretation notes\n",
    "print(f\"\\nInterpretation:\")\n",
    "median_dec = df_win['dec_odds'].median()\n",
    "median_implied = df_win['implied_raw'].median()\n",
    "print(f\"  Median decimal odds: {median_dec:.2f} ({median_implied:.4f} implied)\")\n",
    "print(f\"  → Typical player has ~{100*median_implied:.2f}% win probability (before de-vig)\")\n",
    "\n",
    "print(f\"\\n  Min odds: {df_win['dec_odds'].min():.2f} (favorite)\")\n",
    "print(f\"  Max odds: {df_win['dec_odds'].max():.2f} (extreme longshot)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d2199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created event_id column\n",
      "Unique events: 0\n"
     ]
    }
   ],
   "source": [
    "# Create event_id from tournament/date combination\n",
    "df_win['event_id'] = df_win['tour'].astype(str) + '_' + df_win['event_date'].astype(str)\n",
    "\n",
    "print(f\"Created event_id column\")\n",
    "print(f\"Unique events: {df_win['event_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5948960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 7: DE-VIG ODDS (PROPORTIONAL METHOD)\n",
      "======================================================================\n",
      "\n",
      "Applying proportional de-vig per event...\n",
      "  Processing 0 unique events...\n",
      "  ✓ De-vig complete for all events\n",
      "\n",
      "======================================================================\n",
      "Validation: De-vigged probabilities\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattr\\AppData\\Local\\Temp\\ipykernel_5588\\1100033695.py:88: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(devig_event_group)                # Apply de-vig function\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: p_book'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Critical check: p_book should sum to exactly 1.0 per event\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m event_prob_sums = \u001b[43mdf_win\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mp_book\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sum()\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDe-vigged probability sums per event:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Mean:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_prob_sums.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.15f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mattr\\OneDrive\\Desktop\\Positive_EV_Project\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[39m, in \u001b[36mDataFrameGroupBy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m1\u001b[39m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[32m   1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1950\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mattr\\OneDrive\\Desktop\\Positive_EV_Project\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:245\u001b[39m, in \u001b[36mSelectionMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    246\u001b[39m     ndim = \u001b[38;5;28mself\u001b[39m.obj[key].ndim\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gotitem(key, ndim=ndim)\n",
      "\u001b[31mKeyError\u001b[39m: 'Column not found: p_book'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: Remove Bookmaker Vig (Proportional De-vig Method)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "GOAL: Convert biased market probabilities to fair probabilities\n",
    "\n",
    "THE PROBLEM: Bookmaker Overround (Vig)\n",
    "    - Sum of raw implied probabilities per event > 1.0\n",
    "    - Example: Two players at -110 each (52.38% implied)\n",
    "      → Total: 104.76% (should be 100%)\n",
    "    - Extra 4.76% is bookmaker's built-in profit margin\n",
    "\n",
    "SOLUTION: Proportional De-vig\n",
    "    - Normalize probabilities to sum to exactly 1.0\n",
    "    - Formula: fair_prob[i] = implied_prob[i] / sum(implied_probs)\n",
    "    \n",
    "EXAMPLE:\n",
    "    Raw implied probs: [0.55, 0.55] → Sum = 1.10 (10% vig)\n",
    "    De-vigged probs:   [0.50, 0.50] → Sum = 1.00 (fair)\n",
    "\n",
    "ASSUMPTIONS:\n",
    "    - Bookmaker applies same percentage margin to all players\n",
    "    - Simpler than power/additive methods (good for Sprint 2)\n",
    "    - More sophisticated methods reserved for Sprint 3\n",
    "\n",
    "OUTPUTS:\n",
    "    - p_book: De-vigged fair probability per player\n",
    "    - overround: Bookmaker margin per event (typically 1.15-1.20 for PGA)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 7: DE-VIG ODDS (PROPORTIONAL METHOD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE DE-VIG FUNCTION - FIXED VERSION\n",
    "# ============================================================================\n",
    "def devig_event_group(group):\n",
    "    \"\"\"\n",
    "    Apply proportional de-vig to one event's odds.\n",
    "    \n",
    "    This function is applied per event using groupby().\n",
    "    \n",
    "    Steps:\n",
    "        1. Sum all raw implied probabilities\n",
    "        2. Calculate overround (how much > 1.0)\n",
    "        3. Normalize each probability by dividing by total\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : pd.DataFrame\n",
    "        All rows (players) for a single event\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Same group with two new columns:\n",
    "        - overround: Sum of implied_raw (bookmaker margin)\n",
    "        - p_book: De-vigged fair probability (sums to 1.0)\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying original\n",
    "    group = group.copy()\n",
    "    \n",
    "    # Calculate total (should be > 1.0 due to vig)\n",
    "    total_implied = group['implied_raw'].sum()\n",
    "    \n",
    "    # Store overround for analysis (same value for all rows in group)\n",
    "    group['overround'] = total_implied\n",
    "    \n",
    "    # Proportional normalization - convert Series to array for proportional_devig\n",
    "    # then assign back to ensure proper indexing\n",
    "    devigged_probs = proportional_devig(group['implied_raw'].values)\n",
    "    group['p_book'] = devigged_probs\n",
    "    \n",
    "    return group\n",
    "\n",
    "# ============================================================================\n",
    "# APPLY DE-VIG PER EVENT\n",
    "# ============================================================================\n",
    "print(\"\\nApplying proportional de-vig per event...\")\n",
    "print(f\"  Processing {df_win['event_id'].nunique():,} unique events...\")\n",
    "\n",
    "# Group by event and apply de-vig function\n",
    "# Use transform=False (default) to get full DataFrame back\n",
    "df_win = (\n",
    "    df_win\n",
    "    .groupby('event_id', group_keys=False)  # Process each event separately\n",
    "    .apply(devig_event_group)                # Apply de-vig function\n",
    ")\n",
    "\n",
    "# Reset index to clean up any multi-index issues\n",
    "df_win = df_win.reset_index(drop=True)\n",
    "\n",
    "print(f\"  ✓ De-vig complete for all events\")\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATE DE-VIG RESULTS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Validation: De-vigged probabilities\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Critical check: p_book should sum to exactly 1.0 per event\n",
    "event_prob_sums = df_win.groupby('event_id')['p_book'].sum()\n",
    "\n",
    "print(f\"\\nDe-vigged probability sums per event:\")\n",
    "print(f\"  Mean:   {event_prob_sums.mean():.15f}\")\n",
    "print(f\"  Std:    {event_prob_sums.std():.15e}\")\n",
    "print(f\"  Min:    {event_prob_sums.min():.15f}\")\n",
    "print(f\"  Max:    {event_prob_sums.max():.15f}\")\n",
    "\n",
    "# Check within numerical tolerance (floating point precision)\n",
    "all_sum_to_one = np.allclose(event_prob_sums, 1.0, atol=1e-10)\n",
    "print(f\"\\n  All events sum to 1.0 (±1e-10): {all_sum_to_one}\")\n",
    "\n",
    "if not all_sum_to_one:\n",
    "    # Should not happen with proportional method\n",
    "    print(\"\\n  ⚠️  WARNING: Some events don't sum to exactly 1.0\")\n",
    "    bad_events = event_prob_sums[~np.isclose(event_prob_sums, 1.0, atol=1e-10)]\n",
    "    print(f\"  Problematic events: {len(bad_events)}\")\n",
    "    print(bad_events.head())\n",
    "\n",
    "# ============================================================================\n",
    "# OVERROUND (VIG) ANALYSIS\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Bookmaker Margin (Overround) Analysis\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Get one overround value per event (all players in event have same value)\n",
    "overround_stats = df_win.groupby('event_id')['overround'].first()\n",
    "\n",
    "print(f\"\\nOverround statistics:\")\n",
    "print(overround_stats.describe())\n",
    "\n",
    "# Convert to percentage margin for easier interpretation\n",
    "print(f\"\\nInterpretation (as margin %):\")\n",
    "print(f\"  Min margin:      {100*(overround_stats.min()-1):.2f}%\")\n",
    "print(f\"  25th percentile: {100*(overround_stats.quantile(0.25)-1):.2f}%\")\n",
    "print(f\"  Median margin:   {100*(overround_stats.median()-1):.2f}%\")\n",
    "print(f\"  75th percentile: {100*(overround_stats.quantile(0.75)-1):.2f}%\")\n",
    "print(f\"  Max margin:      {100*(overround_stats.max()-1):.2f}%\")\n",
    "\n",
    "print(f\"\\nTypical PGA outrights vig: 15-20%\")\n",
    "print(f\"Our data median: {100*(overround_stats.median()-1):.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# SHOW BEFORE/AFTER EXAMPLE\n",
    "# ============================================================================\n",
    "# Pick one event and show de-vig effect\n",
    "sample_event = df_win['event_id'].iloc[0]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Example: Event {sample_event}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_df = df_win[df_win['event_id'] == sample_event][\n",
    "    ['player_name', 'dec_odds', 'implied_raw', 'p_book', 'Y']\n",
    "].head(10)\n",
    "\n",
    "print(sample_df.to_string(index=False))\n",
    "\n",
    "# Calculate sums for this event\n",
    "sample_implied_sum = df_win[df_win['event_id'] == sample_event]['implied_raw'].sum()\n",
    "sample_pbook_sum = df_win[df_win['event_id'] == sample_event]['p_book'].sum()\n",
    "\n",
    "print(f\"\\nBefore de-vig (raw implied):  Sum = {sample_implied_sum:.6f}\")\n",
    "print(f\"After de-vig (p_book):        Sum = {sample_pbook_sum:.15f}\")\n",
    "print(f\"Removed vig:                  {100*(sample_implied_sum-1):.2f}%\")\n",
    "\n",
    "print(f\"\\n✓ De-vig successful - probabilities now sum to 1.0 per event\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1eb79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EMERGENCY: Creating de-vig columns manually\n",
      "======================================================================\n",
      "\n",
      "Current df_win shape: (0, 22)\n",
      "\n",
      "⚠️  CRITICAL: df_win is empty!\n",
      "\n",
      "You need to:\n",
      "   1. Restart kernel\n",
      "   2. Re-run Cell 1 (imports)\n",
      "   3. Re-run Cell 2 (load data)\n",
      "   4. Continue through cells 3-9\n",
      "   5. Skip to this fix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot proceed with empty DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   4. Continue through cells 3-9\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   5. Skip to this fix\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot proceed with empty DataFrame\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Verify we have required columns\u001b[39;00m\n\u001b[32m     22\u001b[39m required_cols = [\u001b[33m'\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimplied_raw\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Cannot proceed with empty DataFrame"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EMERGENCY FIX: Manually create de-vig columns\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"EMERGENCY: Creating de-vig columns manually\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if we have data\n",
    "print(f\"\\nCurrent df_win shape: {df_win.shape}\")\n",
    "\n",
    "if len(df_win) == 0:\n",
    "    print(\"\\n⚠️  CRITICAL: df_win is empty!\")\n",
    "    print(\"\\nYou need to:\")\n",
    "    print(\"   1. Restart kernel\")\n",
    "    print(\"   2. Re-run Cell 1 (imports)\")\n",
    "    print(\"   3. Re-run Cell 2 (load data)\")\n",
    "    print(\"   4. Continue through cells 3-9\")\n",
    "    print(\"   5. Skip to this fix\")\n",
    "    raise ValueError(\"Cannot proceed with empty DataFrame\")\n",
    "\n",
    "# Verify we have required columns\n",
    "required_cols = ['event_id', 'implied_raw']\n",
    "missing = [col for col in required_cols if col not in df_win.columns]\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n⚠️  Missing columns: {missing}\")\n",
    "    raise ValueError(f\"Cannot de-vig without: {missing}\")\n",
    "\n",
    "# Calculate overround per event\n",
    "print(\"\\nCalculating overround per event...\")\n",
    "event_overround = df_win.groupby('event_id')['implied_raw'].transform('sum')\n",
    "df_win['overround'] = event_overround\n",
    "\n",
    "# De-vig: divide each implied_raw by the event's overround\n",
    "print(\"De-vigging probabilities...\")\n",
    "df_win['p_book'] = df_win['implied_raw'] / df_win['overround']\n",
    "\n",
    "# Validate\n",
    "print(\"\\nValidation:\")\n",
    "event_sums = df_win.groupby('event_id')['p_book'].sum()\n",
    "print(f\"  Events: {len(event_sums)}\")\n",
    "print(f\"  All sum to 1.0: {np.allclose(event_sums, 1.0, atol=1e-10)}\")\n",
    "print(f\"  Mean overround: {df_win.groupby('event_id')['overround'].first().mean():.4f}\")\n",
    "print(f\"  Median vig: {100*(df_win.groupby('event_id')['overround'].first().median()-1):.1f}%\")\n",
    "\n",
    "print(\"\\n✓ De-vig columns created successfully\")\n",
    "print(f\"✓ Final shape: {df_win.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Positive_EV_Env",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
